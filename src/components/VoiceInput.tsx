"use client";

import { useEffect, useMemo, useRef, useState } from "react";

type Props = {
    onText: (text: string, isFinal: boolean) => void;
};

export default function VoiceInput({ onText }: Props) {
    const [supported, setSupported] = useState(true);
    const [listening, setListening] = useState(false);

    const recRef = useRef<any>(null);
    const isRecordingRef = useRef(false);
    const restartTimerRef = useRef<number | null>(null);

    // é¿å…çˆ¶ç»„ä»¶æ¯æ¬¡ render å¯¼è‡´ effect é‡å»º
    const onTextRef = useRef(onText);
    useEffect(() => {
        onTextRef.current = onText;
    }, [onText]);

    const SpeechRecognitionCtor = useMemo(() => {
        if (typeof window === "undefined") return null;
        return (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition || null;
    }, []);

    useEffect(() => {
        if (!SpeechRecognitionCtor) {
            setSupported(false);
            return;
        }

        const rec = new SpeechRecognitionCtor();
        rec.lang = "zh-CN";
        rec.continuous = true;
        rec.interimResults = true;

        rec.onstart = () => {
            setListening(true);
        };

        rec.onresult = (event: any) => {
            let interim = "";
            let finalText = "";

            for (let i = event.resultIndex; i < event.results.length; i++) {
                const res = event.results[i];
                const txt = res[0]?.transcript ?? "";
                if (res.isFinal) finalText += txt;
                else interim += txt;
            }

            if (interim) onTextRef.current(interim, false);
            if (finalText) onTextRef.current(finalText, true);
        };

        rec.onerror = (e: any) => {
            console.error("SpeechRecognition error:", e);

            // æƒé™ç›¸å…³é”™è¯¯ï¼šä¸è¦å†è‡ªåŠ¨é‡å¯
            if (e?.error === "not-allowed" || e?.error === "service-not-allowed") {
                isRecordingRef.current = false;
                setListening(false);
                return;
            }

            // å…¶å®ƒé”™è¯¯ï¼šç¨åå°è¯•é‡å¯ï¼ˆç”¨æˆ·ä»å¤„äºå½•éŸ³çŠ¶æ€æ‰é‡å¯ï¼‰
            if (isRecordingRef.current) {
                if (restartTimerRef.current) window.clearTimeout(restartTimerRef.current);
                restartTimerRef.current = window.setTimeout(() => {
                    try {
                        rec.start();
                    } catch { }
                }, 300);
            }
        };

        rec.onend = () => {
            // Web Speech å¯èƒ½å› ä¸ºåœé¡¿å°± endï¼›å¦‚æœç”¨æˆ·è¿˜åœ¨å½•éŸ³ï¼Œå°±è‡ªåŠ¨ç»­å¬
            if (isRecordingRef.current) {
                if (restartTimerRef.current) window.clearTimeout(restartTimerRef.current);
                restartTimerRef.current = window.setTimeout(() => {
                    try {
                        rec.start();
                    } catch { }
                }, 200);
            } else {
                setListening(false);
            }
        };

        recRef.current = rec;

        return () => {
            if (restartTimerRef.current) window.clearTimeout(restartTimerRef.current);
            restartTimerRef.current = null;

            try {
                rec.abort?.();
            } catch { }
            try {
                rec.stop?.();
            } catch { }
            recRef.current = null;
        };
    }, [SpeechRecognitionCtor]);

    const start = () => {
        const rec = recRef.current;
        if (!rec) return;

        isRecordingRef.current = true;
        setListening(true);

        try {
            rec.start();
        } catch (e) {
            // é‡å¤ start ä¼š InvalidStateErrorï¼Œå¿½ç•¥å³å¯
            // ä½†ä¸ºäº†â€œç»­å¬â€ï¼Œè¿™é‡Œä¸æŠŠ listening ç½®å› false
            console.warn(e);
        }
    };

    const stop = () => {
        const rec = recRef.current;
        isRecordingRef.current = false;
        setListening(false);

        if (!rec) return;
        try {
            rec.stop();
        } catch { }
    };

    if (!supported) {
        return <div className="text-sm text-gray-600">å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼ˆå»ºè®®ç”¨ Chromeï¼‰ã€‚</div>;
    }

    return (
        <div className="flex gap-2">
            {!listening ? (
                <button className="rounded bg-black text-white px-3 py-2" onClick={start}>
                    ğŸ¤ å¼€å§‹è¯´è¯
                </button>
            ) : (
                <button className="rounded bg-red-600 text-white px-3 py-2" onClick={stop}>
                    â¹ åœæ­¢
                </button>
            )}
            <div className="text-sm text-gray-600 flex items-center">
                {listening ? "æ­£åœ¨è¯†åˆ«â€¦ï¼ˆè‹¥æ— ååº”è¯·æ£€æŸ¥éº¦å…‹é£æƒé™ï¼‰" : "ç‚¹å‡»å¼€å§‹ï¼Œç”¨è¯­éŸ³è¾“å…¥éœ€æ±‚æˆ–è®°è´¦"}
            </div>
        </div>
    );
}